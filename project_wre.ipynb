{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Water Resource Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow1 = np.loadtxt(\"S1flow.txt\", delimiter=',')\n",
    "flow2 = np.loadtxt(\"S2flow.txt\")\n",
    "#Why have 0 in the last values ????\n",
    "#last_index_1 = 2129 \n",
    "#last_index_2 =7239\n",
    "\n",
    "#flow1 = flow1[:last_index_1]\n",
    "#flow2 = flow2[:last_index_2]\n",
    "\n",
    "s1 = pd.Series(flow1)\n",
    "s2 = pd.Series(flow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Hydropower Technical Data\n",
    "\n",
    "Hg1 = 350\n",
    "dHg1 = 0.05 * Hg1\n",
    "Hn1 = Hg1-dHg1\n",
    "\n",
    "Hg2 = 500 \n",
    "dHg2 = 0.05 * Hg2\n",
    "Hn2 = Hg2-dHg2\n",
    "\n",
    "outages = 0.05\n",
    "eff = 0.9\n",
    "\n",
    "#%% Electricity Tarif\n",
    "\n",
    "# Base scenario\n",
    "peak_b = 6 #Us Sc/kWh\n",
    "off_b = 3 \n",
    "\n",
    "# High demand\n",
    "peak_h = 10\n",
    "off_h = 5\n",
    "\n",
    "#Times\n",
    "t_peak = 8 #h/d\n",
    "t_off = 16\n",
    "\n",
    "period = 20 # [y]\n",
    "\n",
    "opex = 0.02 # capex/year\n",
    "\n",
    "#%% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point a\n",
    "Plot the last years of available data for the two stations S1 and S2 one vs the other to see if data are\n",
    "correlated (fit a polynomial function of adequate degree) and use the correlation structure to fill in the missing\n",
    "data. Neglect the noise;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m years \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m365\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# extract last year\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m lasty_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mflow1\u001b[49m[\u001b[38;5;241m-\u001b[39myears:] \n\u001b[1;32m      4\u001b[0m lasty_f2 \u001b[38;5;241m=\u001b[39m flow2[\u001b[38;5;241m-\u001b[39myears:]\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1\u001b[39m,years,years) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'flow1' is not defined"
     ]
    }
   ],
   "source": [
    "years = 365 * 3\n",
    "# extract last year\n",
    "lasty_f1 = flow1[-years:] \n",
    "lasty_f2 = flow2[-years:]\n",
    "\n",
    "x = np.linspace(1,years,years) \n",
    "\n",
    "# Plot last year for both\n",
    "plt.figure(figsize=(6, 3), dpi=300) \n",
    "plt.plot(x,lasty_f1, label = \"flow 1\")\n",
    "plt.plot(x,lasty_f2, label = \"flow 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "correlation = np.corrcoef(lasty_f1, lasty_f2)[0, 1]\n",
    "print(\"Pearson correlation:\", correlation)\n",
    "#%%\n",
    "\n",
    "#Find relation between s1 and s2\n",
    "\n",
    "#Step 1 : id if lag between s1 and s2\n",
    "ind_max1 = np.argmax(lasty_f1)\n",
    "ind_max2 = np.argmax(lasty_f2)\n",
    "print(ind_max1)\n",
    "print(ind_max2)\n",
    "\n",
    "#Step 2 : fit a polynomial\n",
    "n = 1 #degree\n",
    "coef = np.polyfit(lasty_f2, lasty_f1, deg = n)\n",
    "model = np.poly1d(coef) #test model\n",
    "\n",
    "#Step 3 : id missing values in s1 and replace by model\n",
    "ind_missing_s1_Start = 266\n",
    "ind_missing_s1_end = 834\n",
    "\n",
    "ddata = 834-266\n",
    "\n",
    "ind_s2 = len(s2)-(len(s1)-834)\n",
    "\n",
    "s1[ind_missing_s1_Start:ind_missing_s1_end] = model(s2[ind_s2-ddata:ind_s2])\n",
    "\n",
    "#Step 4 : Plot to visualise\n",
    "x = np.arange(1,ddata+1)\n",
    "\n",
    "plt.figure(figsize=(6, 3), dpi=300) \n",
    "plt.plot(x,s1[ind_missing_s1_Start:ind_missing_s1_end])\n",
    "plt.plot(x,s2[ind_s2-ddata:ind_s2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "b) Use the same correlation relationship to prolonge the S1 series to the same \n",
    "    length of the data serie in station 2. This will only be 20 years in total and\n",
    "    we need to have at least 30 years. The swapping technique might be good, but we\n",
    "    need to check if some temporal correlation affects the data before choosing the\n",
    "    years to swap.\n",
    "\"\"\"\n",
    "#build S1 over 20 years\n",
    "total_data_to_add = len(s2)-len(s1)\n",
    "\n",
    "s1_20y = s2.copy()\n",
    "\n",
    "s1_20y[:-len(s1)] = model(s2[:-len(s1)])\n",
    "s1_20y[-len(s1):] = s1[:]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 3), dpi=300) \n",
    "plt.plot(s1_20y)\n",
    "plt.plot(s2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Annual Max serie\n",
    "y = 20 \n",
    "max_s1 = [np.nanmax(s1_20y[i*365:(i+1)*365]) for i in range(y)]\n",
    "max_s1 = np.array(max_s1)\n",
    "\n",
    "# Standardisation and autocorelated serie\n",
    "mean_max = np.mean(max_s1)\n",
    "std_max = np.std(max_s1)\n",
    "z = (max_s1 - mean_max) / std_max\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 3), dpi=300) \n",
    "plt.plot(range(1, y+1), z, marker='o')\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.title(\"Autocorrelated Serie\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Standardized Max Flow\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%% Swapping Coding\n",
    "\n",
    "#Selecting which years -> kind of random, just trying to mix by following trend\n",
    "#such as fluctuating above and below the mean and mixing the intensity \n",
    "\n",
    "swap_y = [7,3,13,2,5,8,10,12,4,17]\n",
    "\n",
    "s1_30y = s1_20y.copy()\n",
    "\n",
    "for i in range(10):\n",
    "    swap = s1_20y[swap_y[i] * 365 : (swap_y[i] + 1) * 365 ]  \n",
    "    s1_30y = np.concatenate((s1_30y, swap))  \n",
    "\n",
    "# Plot the new 30-year time series\n",
    "plt.figure(figsize=(10, 4), dpi=300)\n",
    "plt.plot(s1_30y, label='30-year series')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Flow')\n",
    "plt.title('Flow 1 30 years swapping method')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "c) Build the flow duration curve of the 30 years dataset for reconstructed station \n",
    "    one data and calculate the reference minimal flow for instream flow protection \n",
    "    based on the Q 347 approach;\n",
    "\"\"\"\n",
    "\n",
    "#Weibull sorting\n",
    "sortedQ = np.sort(s1_30y)[::-1]\n",
    "rank = np.arange(1,len(sortedQ)+1)\n",
    "prob = np.array([r / (len(sortedQ)+1) for r in rank]) \n",
    "\n",
    "plt.figure(figsize=(6, 3), dpi=300) \n",
    "plt.plot(prob, sortedQ)\n",
    "plt.xlabel('Exceedance Probability [%]')\n",
    "plt.ylabel('Flow [mÂ³/s]')\n",
    "plt.title('Flow Duration Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Q347\n",
    "\n",
    "ind = np.argmin(np.abs(prob - 0.95))# Find closest match index\n",
    "print(\"Q347 is : \", sortedQ[ind])\n",
    "print(\"Q347 prob. empirique: \",prob[ind])\n",
    "print(\"Should be 0.95 otherwise need to make a curve fitting and find corresponding value for 0.95 !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "d) Obtain the daily mean annual behaviour from data;\n",
    "\"\"\"\n",
    "y = 30\n",
    "daily_mean_annual = [np.mean(s1_30y[i*365:(i+1)*365]) for i in range(y)]\n",
    "print(daily_mean_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "e) Build the monthly mean annual time series, which will be used for the \n",
    "    financial analysis;\n",
    "\"\"\"\n",
    "\n",
    "y = 30\n",
    "month_days = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "\n",
    "monthly_mean = []\n",
    "\n",
    "start = 0\n",
    "for year in range(30):\n",
    "    for i in month_days:\n",
    "        month_s1 = s1_30y[start:start + i]\n",
    "        monthly_mean.append(np.mean(month_s1))\n",
    "        start += i\n",
    "\n",
    "print(monthly_mean)\n",
    "\n",
    "#!!! index 239 gives 0 -> related to year measured data where the last month was 0 Should we add it to the swap ??!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "f) Use the reconstructed data for S1 to build two new series as the sequence of\n",
    "    wet periods and the sequence of dry periods. To the purpose, use the annual\n",
    "    mean as discriminant value for the wet years (above the mean, Aug Dec) and\n",
    "    viceversa. We will use these series later to build the Pareto frontier of \n",
    "    the system\n",
    "\"\"\"\n",
    "\n",
    "wet = []\n",
    "\n",
    "dry = []\n",
    "\n",
    "\n",
    "for j in range(len(daily_mean_annual)):\n",
    "    for i in range(365):\n",
    "        if s1_30y[i+ 365*j]  > daily_mean_annual[j]:\n",
    "            wet.append(s1_30y[i+365*j])\n",
    "        else:\n",
    "            dry.append(s1_30y[i+365*j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
